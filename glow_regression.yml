Glow_regression:
  Version_info: Version 1.0.0, 2020-10-27
  Package_version: <GENERATED BY CI LOOP>
  dialog_group: UKBB
  list_description: Glow regression
  image_color: green
  description: |
    <div style="margin:10px;"><font size = "4">
    <font size="4.5"><p>This report performs Glow regression (https://glow.readthedocs.io/en/latest/tertiary/whole-genome-regression.html).
      The subjects to be included in the analysis can be imported using phenotype and covarites grid(s) open in another tab.
      Important Note: It is advice to perform sample QC to remove outlier samples. We strongly advise restricting the analysis to unrelated subjects from the same ethnic group.</p></font>
    </font>

    <a style="color:#0b68b2;"><b><font size="4">Basic parameters</b></a><table style="border-spacing:10">
    <tr><td><span style="color:#00aeef">Freeze path</span> </td><td>Path to freeze.</td></tr>
    <tr><td><span style="color:#00aeef">Phenotype grid</span> </td><td>A phenotype grid with the first column PN containing the sample IDs, the second column containing the primary outcome (1 for ctrl and 2 for case for a dichotomous/logistic model, or otherwise numerical values for a continuous model), the third column containing the secondary outcome (phenotype 2) etc...  Missing phenotypes must be coded as "NA". No duplicated PNs are allowed. When multiple phenotypes are present, the regression is ran sequentially for each phenotypes. </td></tr>
    <tr><td><span style="color:#00aeef">Covariate grid</span> </td><td>A covariate grid with the first column PN containing the sample IDs, the following column(s) must contain the covariates.  Missing phenotypes must be coded as "NA". Duplicated PNs are not allowed. For gender use 1 for males and 2 for females and "NA" for missing values. </td></tr>
    <tr><td><span style="color:#00aeef">VEP impact</span> </td><td>VEP impact</td></tr>
    <tr><td><span style="color:#00aeef">Kernel</span> </td><td>SKAT kernel</td></tr>
    <tr><td><span style="color:#00aeef">Method</span> </td><td>SKAT method</td></tr>
    <tr><td><span style="color:#00aeef">Name for run</span> </td><td>User created name for run. Can only contain 'Letters, numbers and _'. Used as a part of the result location directory name.</td></tr>
    <tr><td><span style="color:#00aeef">Description</span> </td><td>Short user generated description of run.</td></tr>
    </table></font>

    <a style="color:#0b68b2;"><b><font size="4">Advanced parameters and QC </b></a><table style="border-spacing:10">
    <tr><td><span style="color:#00aeef">Genome range</span></td><td>All (whole genome) or selected region (from an open Genome Browser window) or on the format chr1:100-200.</td></tr>
    <tr><td><span style="color:#00aeef">Hide covar</span></td><td>Hide covar specific results </td></tr>
    <tr><td><span style="color:#00aeef">Variant specific missingness</span></td><td> Filters out all variants with missing call rates exceeding the thresold (by default filter out variants with more than 10% missingness). </td></tr>
    <tr><td><span style="color:#00aeef">Reference path</span></td><td>Path to the reference data directory.</td></tr>
    <tr><td><span style="color:#00aeef">Maximum run time</span></td><td>Maximum time that the job is allowed to run (in hours).</td></tr>
    </table></font>

    <a style="color:#0b68b2;"><b>
    <font size="4">Version Information</b></a><table style="border-spacing:10">
    <font size="3.5">Version 1.0.0, 2019-08-28</font><br>
    <font size="3.5">Package version <GENERATED BY CI LOOP></font><br>
    </table></font>
    </font></div>
  query_type: |
    jobtype:SPARK|timeout:10
  query:
    apiVersion: "sparkoperator.k8s.io/v1beta2"
    kind: SparkApplication
    metadata:
      name: "${job_name.val}"
      namespace: gorkube
    spec:
      type: Python
      pythonVersion: "3"
      mode: cluster
      image: "nextcode/spark:3.1.6"
      imagePullPolicy: Always
      imagePullSecrets:
      - "dockerhub-nextcode-download-credentials"
      mainApplicationFile: local:///mnt/csa/env/dev/projects/ukbb_hg38/user_data/simmi/glowgr/glow_regression.py
      arguments:
      - "/mnt/csa/env/dev/projects/ukbb_hg38/"
      - "${freeze.val}"
      - "${pheno_file.val}"
      - "${covar_file.val}"
      - "${split_file.val}"
      - "${offsets.val}"
      - "${job_name.val}"
      - "${split_contigs.val}"
      - "${repartition.val}"
      sparkVersion: "3.1.1"
      dynamicAllocation:
        enabled: true
        initialExecutors: 2
        minExecutors: 0
        maxExecutors: 100
      volumes:
      - name: volnfs
        persistentVolumeClaim:
          claimName: pvc-gor-nfs-v2
      - name: "spark-local-dir-1"
        persistentVolumeClaim:
          claimName: pvc-phenocat-nfs
      restartPolicy:
        type: OnFailure
        onFailureRetries: 0
        onFailureRetryInterval: 10
        onSubmissionFailureRetries: 0
        onSubmissionFailureRetryInterval: 20
      sparkConf:
        spark.kubernetes.driver.volumes.persistentVolumeClaim.mntcsa.options.claimName: "pvc-gor-nfs-v2"
        spark.kubernetes.driver.volumes.persistentVolumeClaim.mntcsa.mount.path: "/mnt/csa"
        spark.kubernetes.executor.volumes.persistentVolumeClaim.mntcsa.options.claimName: "pvc-gor-nfs-v2"
        spark.kubernetes.executor.volumes.persistentVolumeClaim.mntcsa.mount.path: "/mnt/csa"
        spark.executor.extraJavaOptions: "-Dio.netty.tryReflectionSetAccessible=true"
        spark.sql.execution.arrow.pyspark.enabled: "true"
        spark.sql.execution.arrow.pyspark.fallback.enabled: "false"
        spark.kubernetes.executor.deleteOnTermination: "false"
        spark.kubernetes.authenticate.driver.serviceAccountName: "livy"
        spark.rpc.message.maxSize: "1024"
        spark.driver.maxResultSize: "0"
        spark.task.cpus: "8"
        #spark.kubernetes.memoryOverheadFactor: "0.2"
        #"spark.sql.execution.pandas.convertToArrowArraySafely": "false"
        #spark.executor.pyspark.memory: "28g"
        spark.executor.memoryOverhead: "14g"
        #spark.memory.offHeap.size: "8g"
        #spark.memory.offHeap.enabled: "true"
        spark.driver.memoryOverhead: "8g"
      driver:
        javaOptions: "-Dgor.validation.split.maxcount=10000"
        cores: 4
        coreRequest: "4000m"
        coreLimit: "4000m"
        memory: "8g"
        volumeMounts:
        #- name: volnfs
        #  mountPath: /mnt/csa
        - name: spark-local-dir-1
          mountPath: /tmp/dir1
          subPath: tmp
        labels:
          version: 3.1.1
        serviceAccount: livy
      executor:
        javaOptions: "-Dio.netty.tryReflectionSetAccessible=true -Dgor.validation.split.maxcount=10000"
        cores: 8
        coreRequest: "8000m"
        coreLimit: "8000m"
        instances: 2
        memory: "2g"
        volumeMounts:
        #- name: volnfs
        #  mountPath: /mnt/csa
        - name: spark-local-dir-1
          mountPath: /tmp/dir1
          subPath: tmp
        labels:
          version: 3.1.1
  error_message: |
    <#if !name.val?matches("^\\w+$")>
      "The name can only contain Letters, numbers and _"
    </#if>
  arguments:
   - name: freeze
     display_name: Freeze path
     optional: no
     type: string
     format:
       keywords: "%s"
       values: "%s"
       empty: ""
     single_selection: yes
     values_path: freezes/freeze_list.rep
     quoted: true
     default: freezes/ukbb_500k/imputed_comm_vep95
   #- name: input_file
   #  display_name: Input file
   #  description: Name of the input file
   #  optional: yes
   #  default: "variants.gord"
   #  type: string
   #  display_width: 300
   #- name: bucket_file
   #  display_name: Bucket file
   #  description: Name of the input file
   #  optional: yes
   #  default: "buckets.tsv"
   #  type: string
   #  display_width: 300
   - name: pheno_file
     display_name: Phenotype grid
     description: A phenotype grid must be constructed that has columns Chrom, Pos, Reference, Call, PN, and the outcome parameter, followed by phenotype values. All phenotype and outcome values must be converted to numeric values (e.g., male=1, female=0). You can do this conveniently by filtering a phenotype table to display only the desired columns, and dragging the column headers to order them as required.
     optional: no
     type: string
     display_width: 300
   - name: covar_file
     display_name: Covariate grid
     description: A covariate grid must be constructed.
     optional: yes
     type: string
     display_width: 300
   - name: split_file
     display_name: Split grid
     description: A split grid must be constructed.
     optional: no
     type: string
     display_width: 300
   - name: offsets
     display_name: Offsets
     description: Glowgr phenotype offsets
     optional: yes
     type: string
     display_width: 300
   - name: job_name
     display_name: Job name
     description: Name of job
     optional: no
     type: string
     display_width: 300
   - name: split_contigs
     display_name: Spit contigs
     description: Split contigs
     optional: yes
     type: string
     display_width: 300
   - name: repartition
     display_name: Repartition
     description: Repartition
     optional: yes
     type: string
     display_width: 300
   #- name: vep_impact
   #  display_name: VEP Impact
   #  description: Specify the VEP impact.
   #  type: string
   #  default: "'HIGH','MODERATE'"
   #- name: allele_frequency_threshold
   #  display_name: Allele frequency threshold
   #  description: Specify the allele frequency threshold.
   #  type: string
   #  default: "0.1"
   #- name: comparator
   #  display_name: Allele frequency comparator
   #  description: Specify the allele frequency comparator.
   #  type: string
   #  optional: true
   #  values: ['<','<=','>','>=']   
   #- name: kernel
   #  display_name: Kernel
   #  description: Specify SKAT kernel.
   #  type: string
   #  default: "linear.weighted"
   #  values: ["linear.weighted","linear","IBS","IBS.weighted","quadratic","2wayIX"]
   #- name: method
   #  display_name: Method
   #  description: Specify SKAT method.
   #  type: string
   #  default: "davies"
   #  values: ["davies","liu","liu.mod","optimal.adj","SKATO"]
   #- name: name
   #  display_name: Name for run
   #  description: User created name for run. Can only contain 'Letters, numbers and _'. Used as a part of the result location directory name.
   #  optional: no
   #  type: string
   #  default: ""
   #- name: description
   #  display_name: Description
   #  description: Short user generated description of run.
   #  optional: yes
   #  type: string
   #  default: ""
   #- name: genome_range
   #  display_name: Genome range
   #  description: All (whole genome) or selected region (from an open Genome Browser window).
   #  optional: yes
   #  default: "All"
   #  type: position_range
   #  advanced: yes
   #- name: ref_path
   #  display_name: Reference path
   #  description: Path to the reference data directory.
   #  optional: yes
   #  type: string
   #  default: "ref"
   #  advanced: yes
   #- name: max_run_time
   #  display_name: Maximum run time
   #  description: Maximum time that the job is allowed to run (in hours)
   #  optional: yes
   #  advanced: yes
   #  type: string
   #  values: ["1","2","4","8","12","16","32","64","128","256"]
   #  default: "12"
   #  display_width: 300
